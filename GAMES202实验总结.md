#GAMES202课程lab总结  

##总览  
  本文档记录了我在完成GAMES202（高质量实时渲染）实验过程中的思路和参考资料，包括在实验过程中踩过的一些坑，用来供大家结合实验文档进行参考。由于时间有限，该文档不会写实验文档中重复的内容，所以具体的内容和公式可能要参考实验文档，只涉及我自己的思路和一些实现细节，思路和细节上也可能有一些不完备的部分，欢迎大家随时补充。   
实验主要分为5个专题，每个专题的内容基本独立，涉及到了理论课程中最主干的知识，每个专题内容如下：   
1. 实时阴影（硬阴影和软阴影）以及多光源阴影生成  
2. 实时环境光照（预计算：PRT）  
3. 实时全局光照(Screen Space Reflection算法实现)  
4. 实时高质量着色(GGX,Kulla Conty方法)  
5. 实时光线追踪降噪和降噪加速算法
##实验一
* **生成ShadowMap**：  
   - 任务点一：依据实验文档，这里其实就是一个MVP矩阵的生成和传递函数，主要目标在实验文档中讲的很明确，这里也不再赘述，主要思路即为MVP矩阵接口API的调用，只需传入合适的参数即可完成目标，在这里附上API的查找链接：<https://glmatrix.net/docs/module-mat4.html>  
   - 任务点二：硬阴影的生成部分，需要注意先把查询坐标从-1到1变换到0到1的空间再进行查询，深度的提取可以使用openGL中的texture2D函数。  
* **PCF算法的实现**：  
  PCF算法本质上就是对ShadowMap上的点进行采样，来达到抗锯齿的效果，思路很像MSAA，做法也基本一致，在闫老师课上所讲的采样方式不同于作业框架，作业框架已经给出了两种不同的采样方式，只需要调用即可完成目标，值得注意的是记得规定采样抗锯齿的范围，乘以适当的系数(我用的0.05)以保证阴影的质量，这一点在后续的PCSS中也同样重要。  
* **PCSS算法实现**：  
  PCSS算法可以理解成对PCF算法的应用，其主要思路为使用PCF在伴影范围上执行“抗锯齿”，通过这种方式来达成软阴影的目标。具体细节在实验文档中有提到，在这里对实现时的细节进行一点说明。由于PCSS代表面光源阴影的生成，面光源自身的大小可能需要定义，我定义的是0.5，效果看起来还可以，还有一点需要注意的是调用findBlocker函数得到遮挡范围之后需要得到采样范围。完成以上工作后再将得到的visibility系数传给phong模型生成的color，就能得到效果不错的阴影。  

__PS__: 如果对OpenGL实现PCF有较大的疑问的话，可以参考：<https://learnopengl-cn.github.io/>，里面会有相关的信息。   


* **Bonus部分：多光源的实现**：  
  这部分本身难度一般，但是涉及到Javascript框架，因此可能需要去花费较长的时间理解这一套JavaScript框架上，因此不熟悉Javascrit的话会很费劲。实现思路很简单，多光源就需要传递多个光源数据进shader部分，因此生成的ShadowMap就得有多个。同理，传入的MVP矩阵，光源的强度数据也会因此不同，此部分值的传入需要在PhongMaterial.js中完成，定义多个值方便传入（当然也可以用数组，不过我有点偷懒，就要用多少个就定义了多少个了）。  
  在完成这部分的工作之后，再去loadOBJ.js中增加新增的阴影材质，并将光源定义成数组形式，使用方法：`let lights = renderer.lights.map(light => light.entity);`替换原本的光源即可。增加新的阴影材质在`case 'PhongMaterial'`后增加，注意原本的PhongMaterial此时需要传入的光源参数也要发生变化。  
  接下来的任务就是增加光源了，在engine.js文件中会很清楚的看到有关增加光源方法的注释，这里不再赘述。  
  完成传值工作之后，终于可以去Shader部分完成阴影的生成了，PCSS算法在这里用不同的ShadowMap调用即可，最后将它们一同传给PhongColor，任务完成。  

  ## 实验二
* **预计算球谐系数**  
   - 环境光照：依据球谐函数性质的推导，整个渲染方程可以理解成两个向量的相乘，分别是光照的球谐系数和传递的球谐系数，环境光照部分的系数求取即为本次的第一个任务。代码框架将采样的半球存放在cubemap中，调用作业文档中提到的函数即可实现目标。值得说明的是这里的nori框架其实自带了求解球谐函数系数的函数，可以使用`sh::GetIndex()`函数来得到球谐函数的序号，使用`sh::EvalSH()`来得到对应序号的球谐函数，具体的参数在这里不展示，nori框架中可以找到这些函数的使用方式。  
   - 传输函数球谐系数生成：文档中的伪代码讲述的很详细，其实框架也基本上帮我们写完了所有的伪代码，我们只需要稍微填充一下返回值就行。值得注意的是这里使用了函数标签（虽然我现在还没系统理解），不过它的作用就是在其他函数中可以直接传入该函数标签返回值作为这些其他函数的参数。对于Unshadow和Shadow的不同，也仅仅在判断场景和光线是否有交点上存在差别。  
   - bonus——光线弹射生成间接光部分：在此前生成完直接光后，并没有考虑光线弹射所带来的球谐系数改变，这一部分就是用来完成这个目标的，算法本身的描述在实验文档中已经提到，我在这里给出我的实现思路：构造一个递归函数来对间接光进行计算，递归次数为光线弹射次数，每弹射一次就要完成一次计算，返回结果就是需要增加的间接光系数。每次弹射判断光线打到的位置的判断方式和之前判断光线是否和场景相交一样，只不过此时需要得到交点信息和重心坐标，这部分函数在文档中也有提及，因此不再说明。  

* **实时端球谐光照计算**  
   - 离线端数据检验工作：此前得到了光照系数和传输项系数，现在在实时端完成二者的相乘工作，将得到的数据存放在light.txt和transport.txt中，按照实验文档要求解开注释后，依照指示创建材质，并完成Shader的编写工作即可。Shader在编写过程中使用解析后绑定的变量precomputeL、precomputeLT传入gl_FragColor即可.   
   ___注意: 最后检验结果的时候要在index.html文件中添加Prt材质（自己创建的材质），否则不会显示___  

   - Bonus部分，球谐函数的旋转：球谐函数的旋转的推导过程在实验文档中已经很细致的讲述了，实现的主体位于tool.js中的三个函数，实现的算法本身并不复杂，但是JAVAScript在矩阵运算上有不少坑，我在知乎上看到的一篇文章讲的还可以，基本上囊括了我在写的时候遇到的所有矩阵运算的坑。这里附上链接:<https://zhuanlan.zhihu.com/p/368864653>  .

  ## 实验三
* **直接光照**
  - 直接光照的实现基于漫反射条件下的渲染方程实现，实验文档中的第一个函数`EvalDiffuse(wi,wo,uv)`的功能就是计算漫反射条件下的BRDF项和cos项的乘积，由于漫反射的前提条件，BRDF项就退化为漫反射率除以PI。直接光照实现的另一个函数`EvalDirectionalLight(uv)`的功能就是得到渲染方程中的辐射度，此函数的实现思路也很简单，在材质中已经给我们了辐射度的值`uLightRadience`，把这一项乘以可见度visibility即可。
  - 在上述两项得到以后，在main函数中实现直接光照就显得很直接，需要注意的点在求解BSDF过程中的参数传入上，注意文档所说的起点均位于着色点这句话，因此出射光的出射方向应该是`uCameraPos - vPosWorld_xyz`,入射光的方向很简单，就是光源方向`uLightDir`。

* **Screen Space Ray Tracing**
  - 这部分的工作在于判断光线和场景中的物体是否相交，通过步进的方式判断当前光线所在像素自身的深度和光线本身的深度的大小关系，以此来判断光线是否真的打入到了物体的内部，如果打入到了物体的内部，就说明有交点，找到交点保存下来即可。在后续的间接光照实现中会用到这个交点的信息。

* **间接光照**
  - 间接光照的实现方式伪码说的比较清楚，实验文档中提到的光线方向采样是为对间接光方向的采样，通过框架中提供的那两个函数都能采样得到光线方向，再通过`LocalBasis(n, out b1, out b2)`函数就可以实现局部坐标系到切线坐标系的转换工作了，具体来说就是把该函数得到的三个向量组成一个转换矩阵，和局部空间下的方向向量做乘法就能转换了。
  - 间接光照实现：实验文档中所给出的算法的思路在于从着色点出发寻找可能贡献到着色点的间接光照的着色点，通过采样方向寻找到的交点`hitPos`就是间接光的出发点，这个交点会发出间接光，贡献到当前着色点上。因此当前着色点的间接光的辐射度就为该交点的出射光辐射度，直观来讲，就是`EvaluateBSDF(hitPos) * EvaluateLight(hitPos)`，也即是文档公式的后半部分，前半部分是当前着色点的辐射度和PDF值。在实现的过程中还是要关注起点的位置，避免出错。

* **bonus：Mipmap实现Ray Marching函数加速**
  - Mipmap的思路，即为通过保存多张图的方式对深度进行存储，这样的话在步进的过程中就可以动态决定步长而不用担心采用过大的步长而找不到准确的交点。说回到MipMap本身的生成上，在本算法中生成的MipMap每一次存储的都是上一层MipMap的邻近四个像素深度的最小值，当光线到达该层时，如果没有交点，下一次步进就到上一层去，这样就能有效的增加一次步进的长度。有交点的话就进入该层，进入下层的MipMap寻找交点。不过个人觉得这里的MipMap生成挺麻烦的，需要在JAVAScript框架中修改很多，个人不是很熟悉JAVAScript，因此就没完成实现工作，如果有实现的思路的话也欢迎交流和补充。


  ## 实验四  
* **预计算部分**  
  - 预计算E(u):这部分的积分其实就是一个蒙特卡洛积分，在代码中的求解形式和文档中的略有不同，不过本质相同，均是对渲染方程的求解，文档中的书写形式只是为了和后续的求解公式保持一致。了解了这里是对于普通的蒙特卡洛方法的求解之后就显得没有那么复杂了，先依据文档开头所给出的公式求出BRDF (fr项)，再乘以cos(Theta)，除以PDF即可。值得注意的是这里的返回值是一个三维的向量，框架中也给出了A,B,C三个值，这三个值实质上相等，只是需要反馈到RGB三个通道上使用，因此只需求A之后再将B,C的值赋为A即可。（这里做一下补充说明，文档中的公式大体没有问题，但是字母表示的比较混乱。在代码中，法线方向是N，入射方向是L，出射方向是V，半程（微表面法线）向量是H，还有一点要注意的地方在于，文档中的G项使用的k不是代码中的公式，这里对结果的影响不大，不过为了保持一致，就干脆使用代码框架中的也可。）  

  - bonus部分：这部分的核心思路在于重要性采样，此前的入射方向并没有采取重要性采样的方式，因此在粗糙度较低时会出现噪声，采用重要性采样可以解决这个问题，框架中要我们实现重要性采样的函数得到微表面的法线方向（即半程向量h）这部分的计算公式在实验文档中有讲，我就不再赘述。但值得注意的是在代码框架中注释给出的部分有些多余。注释提示我们把采样得到的半程向量转换到切线空间。但事实上，我们其实已经在切线空间了，这一步其实不需要，我们只用得到相关角度，再调用`vec.h`中的`SphericalToVector(theta, phi)`函数就能得到结果。（这里也再补充一下说明为什么说已经在切线空间里了：我们不难发现在代码中的物体表面法线实际上一直都是(0,0,1)，从这个角度就已经能论证我们的观点了，只有在切线空间法线才能一直是(0,0,1)，世界空间下是不可能的）。在得到了半程向量之后再copy之前求G项的公式，再代入文档中最后给出的weight公式就能得到最终结果了。
  - E_avg：这里直接代公式就行，很简单，不多说。   

* **实时端**  
   - 实时端补充的代码框架和离线端其实很像，多出来的部分完全就是代公式，书写上不存在啥技术含量，不过实时端有个巨坑，助教同学可能是粗心的问题，把`KullaContyMaterial.js`文件中的`uEavgLut`变量多打了一个F，这是个致命BUG，如果不注意很难找到。。。。。   
    

   - Split Sum bonus: 此部分的知识在lecture5中详细提到了，我翻了半天PPT才找到，文档的意思是预计算乘了F项之后的值，并做Split Sum(我们之前的预计算其实没管菲涅尔项，直接默认为1了。),这部分其实在实时端没用到（可以用，但也可以不用，默认是没用到的）。从结果的角度上讲，我们得到的要是一张计算了Split Sum值后的图，这个图也是RGB三通道保存的，不过从结果上我们也可以发现存储方式有点不太一样。之前的图都是黑白，现在是红绿，如果我们查RGB值的话其实很容易发现Split Sum返回的三维向量第三维是0，前两维分别是Split Sum的两个 "split" 开的积分，具体的公式就不再赘述了，闫老师课上有讲。 关于那个具体的积分求法其实也很简单，我们之前的weight就是(fr/F) * cos(theta),再乘上剩下的部分就可以。   

__说明:__ lab4的代码难度其实很低，助教提供的框架很完善，只用完成一些关键的公式即可，不过个人认为这部分的公式推导才是重点，助教在文档中把现成的公式都提供给了我们。这些公式的推导其实很 值得一看，具体的参考资料现在我还没整理，后续再补吧。
    
 ## 实验五
* **单帧降噪**
  - 联合双边滤波的公式在实验文档中已经给出，把每一项分别从当前帧中提取出来做数学运算带入公式即可，公式中的参数在框架中给的也很齐全。从公式的角度来看其实信息很齐全，不过，给出的数学运算中有不少坑，如果直接用编译可能会出大问题，而且报错非常隐蔽，得逐行调试才可以发现。如果正常调用框架 函数，最常见的报错是报除法的错误，会显示说除法的执行时间超时，并且把错误显示到数学库的三维向量Float3和float向量的除法符运算符重载那一行。这个错误的导致原因是除0所导致的错误，不过并不是在我们写Float3类型除float型公式所导致的，问题出在单位化法向量上，为了严谨，会在第三项算normal的时候把法线向量逐一调用数学库中的Normalize函数单位化一遍，而这个函数是不会自己做零向量检查的，换句话说，要是直接调用，在这个函数里就会除0，但除0导致的错误会报到运算符重载上，这就很让人崩溃。除此之外大体上没有什么太大的问题，照着文档的公式写代码就可以了，这里给出一个采样的参考半径kernelRadius，我尝试了16和32两种，这两种都很适用（慢的吓死人）。

* **投影上一帧结果**
  - 这部分给的参数也很完全，只要熟悉MVP矩阵就可以很快写出，虽然框架里有一个矩阵其实没用，框架的`WorldtoScreen`矩阵本质上就是一个P*V矩阵，后面那个toCamera矩阵在这里没用（一度觉得做错了）。做的时候注意像素是否在物体上，屏幕内，这部分就不再赘述了。

* **累计多帧信息**
  - 下面就是整合之前的工作了，框架中的lerp函数就是文档中的公式，我们只用把三个参数正确计算就行，Clamp操作框架也提供了，剩下的工作就是计算方差和期望了。这部分的求取就是概率论的基础知识了，我个人带入的是每一个参数的原始公式，个人感觉求取方差也可以直接带期望求解，减少计算量，两种方法对结果的影响都不大。

* **bonus：À-TrousWavelet单帧降噪加速**
  - 单帧降噪为了得到良好的效果，滤波核尽量选的越大越好，不过太大的滤波范围也会导致程序运行的极慢，如果滤波核选16，我的电脑直接运行的话第一个场景要23分钟，加速后能达到5分钟，第二个场景没敢试不加速的情况，加速都要一个小时，从这里也不难看出加速的必要性。说回到加速算法本身，该算法的核心思想就是在保证采样范围和精度的情况下尽量减少采样的数量，多次完成pass，每次pass采样5*5个sample。这里有个坑，由于算法本身是多趟pass的，而代码框架为了加速将代码进行了一定的并行化，采用openMP的方式执行了多线程执行，这就导致了openMP里面跑多趟pass的时候会出问题，可能你某个线程这个pass没跑完，另一个线程已经跑完要用这个pass在filter后的结果了，这样会出大问题。因此要把pass写在openMP外面，让openMP自己独立运行。算法每次的pass都会把上一次filter之后的结果进行间隔采样，每PASS采样25个sample. 说到这里，问题的核心就显而易见了，如何存上一个filter的结果，这里提供两个思路。第一个思路是把每一趟pass的结果都存在在一个新建的缓冲区里，把所有的缓冲区放在一个队列里存取使用即可。第二个思路的空间开销会低一些，只用两个缓冲区就行，每一次交替进行采样和存储，相邻两次pass的存和取刚好反过来，交替执行，也能实现算法。


